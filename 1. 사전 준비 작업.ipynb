{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. 사전 준비 작업\n",
    "- https://www.philschmid.de/fsdp-qlora-llama3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 필요 패키지 설치 및 local docker repo 위치 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "install_needed = True\n",
    "# install_needed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already revised\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#!/bin/bash\n",
    "\n",
    "DAEMON_PATH=\"/etc/docker\"\n",
    "MEMORY_SIZE=10G\n",
    "\n",
    "FLAG=$(cat $DAEMON_PATH/daemon.json | jq 'has(\"data-root\")')\n",
    "# echo $FLAG\n",
    "\n",
    "if [ \"$FLAG\" == true ]; then\n",
    "    echo \"Already revised\"\n",
    "else\n",
    "    sudo service docker stop\n",
    "    echo \"Add data-root and default-shm-size=$MEMORY_SIZE\"\n",
    "    sudo cp $DAEMON_PATH/daemon.json $DAEMON_PATH/daemon.json.bak\n",
    "    sudo cat $DAEMON_PATH/daemon.json.bak | jq '. += {\"data-root\":\"/home/ec2-user/SageMaker/.container/docker\",\"default-shm-size\":\"'$MEMORY_SIZE'\"}' | sudo tee $DAEMON_PATH/daemon.json > /dev/null\n",
    "    sudo rsync -aP /var/lib/docker /home/ec2-user/SageMaker/.container\n",
    "    sudo service docker start\n",
    "    echo \"Docker Restart\"\n",
    "fi\n",
    "\n",
    "# sudo curl -L \"https://github.com/docker/compose/releases/download/v2.7.0/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\n",
    "# sudo chmod +x /usr/local/bin/docker-compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import IPython\n",
    "\n",
    "if install_needed:\n",
    "    print(\"installing deps and restarting kernel\")\n",
    "    !{sys.executable} -m pip install --upgrade pip --quiet\n",
    "    !{sys.executable} -m pip install -U sagemaker transformers datasets peft trl bitsandbytes wandb mlflow==2.13.2 sagemaker-mlflow==0.1.0 --quiet\n",
    "    IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are going to use Sagemaker in a local environment. You need access to an IAM Role with the required permissions for Sagemaker. You can find [here](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html) more about it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from pathlib import Path\n",
    "from time import strftime\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/llama-3-1-kor-bllossom-8b'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.227.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['HF_DATASETS_CACHE'] = '/home/ec2-user/SageMaker/.cache'\n",
    "os.environ['HF_CACHE_HOME'] = '/home/ec2-user/SageMaker/.cache'\n",
    "os.environ['HUGGINGFACE_HUB_CACHE'] = '/home/ec2-user/SageMaker/.cache'\n",
    "# os.environ['TRANSFORMERS_HOME'] = '/home/ec2-user/SageMaker/.cache'\n",
    "# os.environ['HF_HOME'] = '/home/ec2-user/SageMaker/.cache'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model, tokenizer 저장 및 S3 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer\n",
    ")\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import huggingface_hub\n",
    "from trl import setup_chat_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_model_id = \"MLP-KTLim/llama-3-Korean-Bllossom-8B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8ba8dd506d44f5829c67025faac89b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 12 files:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/2024/llama-3-on-sagemaker/llama-3-Korean-Bllossom-8B'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# custom_draft_model_id=\"meta-llama/Meta-Llama-3-8B\"\n",
    "\n",
    "hf_local_download_dir = Path.cwd() / \"llama-3-Korean-Bllossom-8B\"\n",
    "hf_local_download_dir.mkdir(exist_ok=True)\n",
    "\n",
    "huggingface_hub.snapshot_download(\n",
    "    repo_id=test_model_id,\n",
    "    revision=\"main\",\n",
    "    local_dir=hf_local_download_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(test_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc537fbd11d2468a8749c4a0d852dcfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    test_model_id,\n",
    "    # torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, tokenizer = setup_chat_format(model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리 및 S3 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(f'./model_weight/{test_model_id}')\n",
    "model.save_pretrained(f'./model_weight/{test_model_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input spec (in this case, just an S3 path): s3://sagemaker-us-west-2-322537213286/sagemaker/llama-3-1-kor-bllossom-8b/model_weight/MLP-KTLim/llama-3-Korean-Bllossom-8B\n"
     ]
    }
   ],
   "source": [
    "model_weight_path = sagemaker_session.upload_data(path=f'./model_weight/{test_model_id}', bucket=bucket, key_prefix=f\"{prefix}/model_weight/{test_model_id}\")\n",
    "print('input spec (in this case, just an S3 path): {}'.format(model_weight_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 주가 증권 보고서 gemini 데이터셋\n",
    "hkcode_dataset = \"uiyong/gemini_result_kospi_0517_jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(hkcode_dataset, split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 230\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dff2bd99b7f4e228d1ad98767e4e9c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518d7bfacaf24d1cb66ebb2c145c7f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded data to:\n",
      "training dataset to: s3://sagemaker-us-west-2-322537213286/sagemaker/llama-3-1-kor-bllossom-8b/gemini_result_kospi_0517/train/train_dataset.json\n",
      "test dataset to: s3://sagemaker-us-west-2-322537213286/sagemaker/llama-3-1-kor-bllossom-8b/gemini_result_kospi_0517/test/test_dataset.json\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'gemini_result_kospi_0517'\n",
    "\n",
    "# save train_dataset to s3\n",
    "local_training_input_path = f'{Path.cwd()}/dataset/train'\n",
    "dataset.to_json(f\"{local_training_input_path}/train_dataset.json\", orient=\"records\", force_ascii=False)\n",
    "training_input_path = sagemaker_session.upload_data(path=f\"{local_training_input_path}/train_dataset.json\", bucket=bucket, key_prefix=f\"{prefix}/{dataset_name}/train\")\n",
    "\n",
    "# save test_dataset to s3\n",
    "local_test_input_path = f'{Path.cwd()}/dataset/test'\n",
    "dataset.to_json(f\"{local_test_input_path}/test_dataset.json\", orient=\"records\", force_ascii=False)\n",
    "test_input_path = sagemaker_session.upload_data(path=f\"{local_test_input_path}/test_dataset.json\", bucket=bucket, key_prefix=f\"{prefix}/{dataset_name}/test\")\n",
    "\n",
    "print(\"uploaded data to:\")\n",
    "print(f\"training dataset to: {training_input_path}\")\n",
    "print(f\"test dataset to: {test_input_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mlflow policy\n",
    "```python\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",    \n",
    "    \"Statement\": [        \n",
    "        {            \n",
    "            \"Effect\": \"Allow\",            \n",
    "            \"Action\": [\n",
    "                \"sagemaker-mlflow:*\",\n",
    "                \"sagemaker:CreateMlflowTrackingServer\",\n",
    "                \"sagemaker:UpdateMlflowTrackingServer\",\n",
    "                \"sagemaker:DeleteMlflowTrackingServer\",\n",
    "                \"sagemaker:StartMlflowTrackingServer\",\n",
    "                \"sagemaker:StopMlflowTrackingServer\",\n",
    "                \"sagemaker:CreatePresignedMlflowTrackingServerUrl\"\n",
    "            ],            \n",
    "            \"Resource\": \"*\"        \n",
    "        }        \n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "#### SSM access policy\n",
    "arn:aws:iam::aws:policy/AmazonSSMFullAccess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker mlflow 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flag = \"240801\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker, boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "bucket_name = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sess.boto_region_name\n",
    "\n",
    "iam_client = boto3.client(\"iam\")\n",
    "sts_client = boto3.client(\"sts\")\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker Execution Role Name: AmazonSageMaker-ExecutionRole-20230604T222555\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "sagemaker_role_name = get_execution_role().rsplit('/', 1)[-1]\n",
    "print (f\"SageMaker Execution Role Name: {sagemaker_role_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'e44c5b66-3eed-42db-81d2-fc3998a00e0d',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Thu, 01 Aug 2024 12:45:22 GMT',\n",
       "   'x-amzn-requestid': 'e44c5b66-3eed-42db-81d2-fc3998a00e0d',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '212'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_mlflow_execution_policy = {\n",
    "    \"Version\": \"2012-10-17\",    \n",
    "    \"Statement\": [        \n",
    "        {            \n",
    "            \"Effect\": \"Allow\",            \n",
    "            \"Action\": [\n",
    "                \"sagemaker-mlflow:*\",\n",
    "                \"sagemaker:CreateMlflowTrackingServer\",\n",
    "                \"sagemaker:UpdateMlflowTrackingServer\",\n",
    "                \"sagemaker:DeleteMlflowTrackingServer\",\n",
    "                \"sagemaker:StartMlflowTrackingServer\",\n",
    "                \"sagemaker:StopMlflowTrackingServer\",\n",
    "                \"sagemaker:CreatePresignedMlflowTrackingServerUrl\"\n",
    "            ],            \n",
    "            \"Resource\": \"*\"        \n",
    "        }        \n",
    "    ]\n",
    "}\n",
    "\n",
    "sagemaker_role_name = get_execution_role().rsplit('/', 1)[-1]\n",
    "sagemaker_exe_role_arn = get_execution_role()\n",
    "\n",
    "sm_mlflow_execution_policy_info = iam_client.create_policy(\n",
    "    PolicyName=f\"sm-mlflow-execution-policy-{flag}\",\n",
    "    PolicyDocument=json.dumps(sm_mlflow_execution_policy)\n",
    ")\n",
    "\n",
    "sm_mlflow_execution_policy_arn = sm_mlflow_execution_policy_info[\"Policy\"][\"Arn\"]\n",
    "\n",
    "# Attach the policy to the MLflow role\n",
    "iam_client.attach_role_policy(\n",
    "    RoleName=sagemaker_role_name, PolicyArn=sm_mlflow_execution_policy_arn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tracking_server_name = f\"mlflow-tracking-{flag}\"\n",
    "mlflow_tracking_server_role_name = f\"mlflow-tracking-server-{flag}\"\n",
    "tracking_server_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '01a8ba8c-2bbc-436d-a6ea-ff640fe3ab0e',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Thu, 01 Aug 2024 12:45:24 GMT',\n",
       "   'x-amzn-requestid': '01a8ba8c-2bbc-436d-a6ea-ff640fe3ab0e',\n",
       "   'content-type': 'text/xml',\n",
       "   'content-length': '212'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow_trust_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\"Service\": [\"sagemaker.amazonaws.com\"]},\n",
    "            \"Action\": \"sts:AssumeRole\",\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Create role for MLflow\n",
    "mlflow_role = iam_client.create_role(\n",
    "    RoleName=mlflow_tracking_server_role_name,\n",
    "    AssumeRolePolicyDocument=json.dumps(mlflow_trust_policy)\n",
    ")\n",
    "mlflow_role_arn = mlflow_role[\"Role\"][\"Arn\"]\n",
    "\n",
    "# Create policy for S3 and SageMaker Model Registry\n",
    "sm_s3_model_registry_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:Get*\",\n",
    "                \"s3:Put*\",\n",
    "                \"s3:List*\",\n",
    "                \"sagemaker:AddTags\",\n",
    "                \"sagemaker:CreateModelPackageGroup\",\n",
    "                \"sagemaker:CreateModelPackage\",\n",
    "                \"sagemaker:UpdateModelPackage\",\n",
    "                \"sagemaker:DescribeModelPackageGroup\",\n",
    "            ],\n",
    "            \"Resource\": \"*\",\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "mlflow_s3_sm_model_registry_iam_policy = iam_client.create_policy(\n",
    "    PolicyName=f\"mlflow-s3-sm-model-registry-{flag}\", PolicyDocument=json.dumps(sm_s3_model_registry_policy)\n",
    ")\n",
    "mlflow_s3_sm_model_registry_iam_policy_arn = mlflow_s3_sm_model_registry_iam_policy[\"Policy\"][\"Arn\"]\n",
    "\n",
    "# Attach the policy to the MLflow role\n",
    "iam_client.attach_role_policy(\n",
    "    RoleName=mlflow_tracking_server_role_name, \n",
    "    PolicyArn=mlflow_s3_sm_model_registry_iam_policy_arn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TrackingServerArn': 'arn:aws:sagemaker:us-west-2:322537213286:mlflow-tracking-server/mlflow-tracking-240801',\n",
       " 'ResponseMetadata': {'RequestId': 'd4ceef0b-6f17-47b9-947b-9d1b35f70cad',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'd4ceef0b-6f17-47b9-947b-9d1b35f70cad',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '110',\n",
       "   'date': 'Thu, 01 Aug 2024 12:56:20 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_client.create_mlflow_tracking_server(\n",
    "    TrackingServerName=tracking_server_name,\n",
    "    ArtifactStoreUri=f\"s3://{bucket_name}/{tracking_server_name}\",\n",
    "    TrackingServerSize=\"Small\",\n",
    "    MlflowVersion=\"2.13.2\",\n",
    "    RoleArn=mlflow_role_arn,\n",
    "    AutomaticModelRegistration=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:sagemaker:us-west-2:322537213286:mlflow-tracking-server/mlflow-tracking-240801'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracking_server_arn = (\n",
    "    f\"arn:aws:sagemaker:{region}:{account_id}:mlflow-tracking-server/{tracking_server_name}\"\n",
    ")\n",
    "tracking_server_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Creating\n",
      "mlflow training server is Active\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "while True:\n",
    "    ml_tracking_server = sm_client.describe_mlflow_tracking_server(TrackingServerName=tracking_server_name)\n",
    "    if ml_tracking_server['IsActive'] == 'Active':\n",
    "        print(\"mlflow training server is Active\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"mlflow training server is Creating\")\n",
    "        time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking_server_arn: arn:aws:sagemaker:us-west-2:322537213286:mlflow-tracking-server/mlflow-tracking-240801\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(tracking_server_arn)\n",
    "print (f'tracking_server_arn: {tracking_server_arn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'llama-3-1-kor-bllossom-8b-240801'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = prefix.split(\"/\")[-1] + f\"-{flag}\"\n",
    "experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.create_experiment(name=experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RegisteredModel: aliases={}, creation_timestamp=1722519207822, description='', last_updated_timestamp=1722519207822, latest_versions=[], name='llama-3-1-kor-bllossom-8b', tags={}>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registered_model = 'llama-3-1-kor-bllossom-8b'\n",
    "\n",
    "from mlflow import MlflowClient\n",
    "client = MlflowClient()\n",
    "client.create_registered_model(registered_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tracking_server_name=\"mlflow-tracking-240801\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AuthorizedUrl': 'https://t-d8yxtuyd6uuh.us-west-2.experiments.sagemaker.aws/auth?authToken=eyJhbGciOiJIUzI1NiJ9.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.yRmSqA6xkS67CvC6Efst995AEzpKLLnQzz287QbBDO4',\n",
       " 'ResponseMetadata': {'RequestId': '4a686c95-c292-4c69-8283-f667d59c2b86',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '4a686c95-c292-4c69-8283-f667d59c2b86',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '3518',\n",
       "   'date': 'Thu, 01 Aug 2024 23:32:29 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "sm_client.create_presigned_mlflow_tracking_server_url(TrackingServerName=tracking_server_name, \n",
    "                                                      ExpiresInSeconds=300,\n",
    "                                                      SessionExpirationDurationInSeconds=43200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'test_model_id' (str)\n",
      "Stored 'bucket' (str)\n",
      "Stored 'prefix' (str)\n",
      "Stored 'model_weight_path' (str)\n",
      "Stored 'training_input_path' (str)\n",
      "Stored 'test_input_path' (str)\n",
      "Stored 'local_training_input_path' (str)\n",
      "Stored 'local_test_input_path' (str)\n",
      "Stored 'tracking_server_arn' (str)\n",
      "Stored 'experiment_name' (str)\n",
      "Stored 'registered_model' (str)\n",
      "test_model_id : MLP-KTLim/llama-3-Korean-Bllossom-8B\n",
      "bucket : sagemaker-us-west-2-322537213286\n",
      "prefix : sagemaker/llama-3-1-kor-bllossom-8b\n",
      "model_weight_path : s3://sagemaker-us-west-2-322537213286/sagemaker/llama-3-1-kor-bllossom-8b/model_weight/MLP-KTLim/llama-3-Korean-Bllossom-8B\n",
      "training_input_path : s3://sagemaker-us-west-2-322537213286/sagemaker/llama-3-1-kor-bllossom-8b/gemini_result_kospi_0517/train/train_dataset.json\n",
      "test_input_path : s3://sagemaker-us-west-2-322537213286/sagemaker/llama-3-1-kor-bllossom-8b/gemini_result_kospi_0517/test/test_dataset.json\n",
      "local_training_input_path : /home/ec2-user/SageMaker/2024/llama-3-on-sagemaker/dataset/train\n",
      "local_test_input_path : /home/ec2-user/SageMaker/2024/llama-3-on-sagemaker/dataset/test\n",
      "tracking_server_arn : arn:aws:sagemaker:us-west-2:322537213286:mlflow-tracking-server/mlflow-tracking-240801\n",
      "experiment_name : llama-3-1-kor-bllossom-8b-240801\n",
      "registered_model : llama-3-1-kor-bllossom-8b\n"
     ]
    }
   ],
   "source": [
    "%store test_model_id\n",
    "%store bucket\n",
    "%store prefix\n",
    "%store model_weight_path\n",
    "%store training_input_path\n",
    "%store test_input_path\n",
    "%store local_training_input_path\n",
    "%store local_test_input_path\n",
    "%store tracking_server_arn\n",
    "%store experiment_name\n",
    "%store registered_model\n",
    "%store tracking_server_name\n",
    "\n",
    "print(f\"test_model_id : {test_model_id}\")\n",
    "print(f\"bucket : {bucket}\")\n",
    "print(f\"prefix : {prefix}\")\n",
    "print(f\"model_weight_path : {model_weight_path}\")\n",
    "print(f\"training_input_path : {training_input_path}\")\n",
    "print(f\"test_input_path : {test_input_path}\")\n",
    "print(f\"local_training_input_path : {local_training_input_path}\")\n",
    "print(f\"local_test_input_path : {local_test_input_path}\")\n",
    "print(f\"tracking_server_arn : {tracking_server_arn}\")\n",
    "print(f\"experiment_name : {experiment_name}\")\n",
    "print(f\"registered_model : {registered_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
